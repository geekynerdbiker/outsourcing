{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.datasets import cifar10 \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.optimizers import SGD \n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "def load_cifar10_data(img_rows, img_cols):\n",
    "\n",
    "   (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "   X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train])\n",
    "   X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:,:]])\n",
    "\n",
    "   Y_train = to_categorical(Y_train, num_classes)\n",
    "   Y_valid = to_categorical(Y_valid, num_classes)\n",
    "   X_train = X_train.astype('float32')\n",
    "   X_valid = X_valid.astype('float32')\n",
    "\n",
    "    # preprocess data\n",
    "   X_train = X_train / 255.0\n",
    "   X_valid = X_valid / 255.0\n",
    "\n",
    "   return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_cifar10_data(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(x,\n",
    "                     filters_1x1,\n",
    "                     filters_3x3_reduce,\n",
    "                     filters_3x3,\n",
    "                     filters_5x5_reduce,\n",
    "                     filters_5x5,\n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    \n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
    "\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
    "\n",
    "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
    "\n",
    "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.keras.initializers.glorot_uniform()\n",
    "bias_init = tf.keras.initializers.Constant(value=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(32, 32, 3))\n",
    "\n",
    "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
    "#x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
    "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=64,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=128,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=32,\n",
    "                     filters_pool_proj=32,\n",
    "                     name='inception_3a')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=128,\n",
    "                     filters_3x3_reduce=128,\n",
    "                     filters_3x3=192,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=96,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_3b')\n",
    "\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=192,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=208,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=48,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4a')\n",
    "\n",
    "\n",
    "classifier_1 = AveragePooling2D((2, 2), strides=2)(x)\n",
    "classifier_1 = Conv2D(128, (1, 1), padding='same', activation='relu')(classifier_1)\n",
    "classifier_1 = Flatten()(classifier_1)\n",
    "classifier_1 = Dense(128, activation='relu')(classifier_1)\n",
    "classifier_1 = Dropout(0.5)(classifier_1)\n",
    "classifier_1 = Dense(10, activation='softmax', name='auxilliary_output_1')(classifier_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_layer, classifier_1, name='googlenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"googlenet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_7x7/2 (Conv2D)           (None, 16, 16, 64)   9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_1_3x3/2 (MaxPooling2D) (None, 8, 8, 64)     0           conv_1_7x7/2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2b_3x3/1 (Conv2D)          (None, 8, 8, 192)    110784      max_pool_1_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_2_3x3/2 (MaxPooling2D) (None, 4, 4, 192)    0           conv_2b_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 4, 4, 96)     18528       max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 4, 16)     3088        max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 4, 4, 192)    0           max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 4, 4, 64)     12352       max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 4, 4, 128)    110720      conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 4, 4, 32)     12832       conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 4, 4, 32)     6176        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a (Concatenate)      (None, 4, 4, 256)    0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 4, 4, 128)    32896       inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 4, 4, 32)     8224        inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 4, 4, 256)    0           inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 4, 4, 128)    32896       inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 4, 4, 192)    221376      conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 96)     76896       conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 4, 4, 64)     16448       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b (Concatenate)      (None, 4, 4, 480)    0           conv2d_62[0][0]                  \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_3_3x3/2 (MaxPooling2D) (None, 2, 2, 480)    0           inception_3b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 2, 2, 96)     46176       max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 16)     7696        max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 2, 2, 480)    0           max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 2, 2, 192)    92352       max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 2, 2, 208)    179920      conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 2, 2, 48)     19248       conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 2, 2, 64)     30784       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a (Concatenate)      (None, 2, 2, 512)    0           conv2d_68[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 512)    0           inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 1, 1, 128)    65664       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 128)          0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "auxilliary_output_1 (Dense)     (None, 10)           1290        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,132,330\n",
      "Trainable params: 1,132,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.01, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 53s 134ms/step - loss: 2.2419 - accuracy: 0.1354 - val_loss: 1.9231 - val_accuracy: 0.2530\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.01, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 59s 150ms/step - loss: 1.8345 - accuracy: 0.2888 - val_loss: 1.5535 - val_accuracy: 0.4087\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.01, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 82s 210ms/step - loss: 1.5993 - accuracy: 0.4003 - val_loss: 1.3759 - val_accuracy: 0.4918\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.01, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 62s 158ms/step - loss: 1.4413 - accuracy: 0.4751 - val_loss: 1.2938 - val_accuracy: 0.5296\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.01, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 74s 188ms/step - loss: 1.3127 - accuracy: 0.5236 - val_loss: 1.1701 - val_accuracy: 0.5756\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.01, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 76s 195ms/step - loss: 1.1949 - accuracy: 0.5716 - val_loss: 1.0725 - val_accuracy: 0.6161\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.01, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 66s 169ms/step - loss: 1.1011 - accuracy: 0.6090 - val_loss: 1.0661 - val_accuracy: 0.6169\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.0095999995, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 83s 213ms/step - loss: 1.0087 - accuracy: 0.6396 - val_loss: 1.0811 - val_accuracy: 0.6113\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.0095999995, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 63s 162ms/step - loss: 0.9340 - accuracy: 0.6699 - val_loss: 0.9942 - val_accuracy: 0.6538\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.0095999995, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 86s 221ms/step - loss: 0.8791 - accuracy: 0.6977 - val_loss: 0.9028 - val_accuracy: 0.6834\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.0095999995, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 63s 161ms/step - loss: 0.8102 - accuracy: 0.7189 - val_loss: 0.9580 - val_accuracy: 0.6749\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0095999995, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 84s 216ms/step - loss: 0.7735 - accuracy: 0.7337 - val_loss: 0.8834 - val_accuracy: 0.6922\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0095999995, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 64s 164ms/step - loss: 0.7037 - accuracy: 0.7576 - val_loss: 0.8774 - val_accuracy: 0.7055\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.0095999995, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 81s 208ms/step - loss: 0.6594 - accuracy: 0.7755 - val_loss: 0.8870 - val_accuracy: 0.6990\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.0095999995, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 0.6228 - accuracy: 0.7878 - val_loss: 0.9064 - val_accuracy: 0.7066\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.009215999, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 86s 221ms/step - loss: 0.5558 - accuracy: 0.8088 - val_loss: 0.9293 - val_accuracy: 0.6980\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.009215999, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 67s 172ms/step - loss: 0.5250 - accuracy: 0.8203 - val_loss: 0.8494 - val_accuracy: 0.7209\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.009215999, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 77s 198ms/step - loss: 0.4915 - accuracy: 0.8362 - val_loss: 0.8743 - val_accuracy: 0.7275\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.009215999, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 80s 205ms/step - loss: 0.4504 - accuracy: 0.8476 - val_loss: 0.8856 - val_accuracy: 0.7307\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.009215999, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 77s 196ms/step - loss: 0.4031 - accuracy: 0.8634 - val_loss: 0.9216 - val_accuracy: 0.7261\n",
      "Epoch 21/25\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.009215999, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 84s 214ms/step - loss: 0.3840 - accuracy: 0.8703 - val_loss: 0.9164 - val_accuracy: 0.7321\n",
      "Epoch 22/25\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.009215999, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.3404 - accuracy: 0.8863 - val_loss: 0.9141 - val_accuracy: 0.7311\n",
      "Epoch 23/25\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.009215999, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 86s 220ms/step - loss: 0.3278 - accuracy: 0.8874 - val_loss: 1.0152 - val_accuracy: 0.7295\n",
      "Epoch 24/25\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.00884736, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 65s 167ms/step - loss: 0.3069 - accuracy: 0.8959 - val_loss: 0.9636 - val_accuracy: 0.7377\n",
      "Epoch 25/25\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.00884736, shape=(), dtype=float32).\n",
      "391/391 [==============================] - 86s 221ms/step - loss: 0.2623 - accuracy: 0.9113 - val_loss: 1.0702 - val_accuracy: 0.7323\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 25\n",
    "initial_lrate = 0.01\n",
    "\n",
    "def decay(epoch, steps=100):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.96\n",
    "    epochs_drop = 8\n",
    "    lrate = initial_lrate * tf.math.pow(drop, tf.math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "sgd = SGD(lr=initial_lrate, momentum=0.9, nesterov=False)\n",
    "\n",
    "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                    epochs=epochs, batch_size=128, callbacks=[lr_sc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
