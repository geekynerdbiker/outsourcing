{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0NSl3gi88cWe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "da3b4d08-8fc6-4318-dc6f-d8805c688d08"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch_fid'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e66d6f9b50ff>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_fid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfid_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_default_https_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_unverified_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_fid'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.autograd as autograd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pytorch_fid import fid_score\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkGtxGBR8cWf"
      },
      "source": [
        "### 1. Data Preparation & Data Preprocessing:    - Score: 10 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUHLuLDe8cWg"
      },
      "outputs": [],
      "source": [
        "pth_to_imgs = \"img_align_celeba\"\n",
        "imgs = glob.glob(os.path.join(pth_to_imgs, \"*\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z62yUWwX8cWg"
      },
      "outputs": [],
      "source": [
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, img_paths, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFaD72AJ8cWg"
      },
      "source": [
        "### ì´ë¯¸ì§€ ì „ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fgtSsTJ8cWg"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTTH3K2U8cWg"
      },
      "outputs": [],
      "source": [
        "dataset = CelebADataset(imgs, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "images = next(data_iter)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(((images[i].permute(1, 2, 0) + 1) / 2).numpy())\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQm6DXBb8cWh"
      },
      "source": [
        "### 2. Generator and Discriminator: - Score: 20 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-oJemfA8cWh"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.init_size = 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(z_dim, 256 * self.init_size * self.init_size))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(32, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 256, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdWXCHow8cWh"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(3, 32, 4, 2, 1, bias=False)),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(nn.Conv2d(32, 64, 4, 2, 1, bias=False)),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, 2, 1, bias=False)),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(nn.Conv2d(128, 256, 4, 2, 1, bias=False)),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out.view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgm2iJ-C8cWh"
      },
      "outputs": [],
      "source": [
        "def gradient_penalty(D, real_data, fake_data, device):\n",
        "    alpha = torch.rand(real_data.size(0), 1, 1, 1, device=device)\n",
        "    interpolates = (alpha * real_data + (1 - alpha) * fake_data).requires_grad_(True)\n",
        "    d_interpolates = D(interpolates)\n",
        "    gradients = autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=torch.ones_like(d_interpolates),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95_sk9X48cWh"
      },
      "source": [
        "### 3. Training: - Score: 10 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdWYDklb8cWi"
      },
      "outputs": [],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "z_dim = 100\n",
        "G = Generator(z_dim).to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "if os.path.isfile(\"saved_models/generator.pth\") :\n",
        "    G.load_state_dict(torch.load('saved_models/generator.pth', map_location=device))\n",
        "    D.load_state_dict(torch.load('saved_models/discriminator.pth', map_location=device))\n",
        "    G.eval()\n",
        "    D.eval()\n",
        "    print(\"Generatorì™€ Discriminator ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\")\n",
        "\n",
        "else :\n",
        "    optimizer_G = optim.Adam(G.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "    optimizer_D = optim.Adam(D.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
        "    lambda_gp = 10\n",
        "    num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPXMpoei8cWi"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile(\"saved_models/generator.pth\"):\n",
        "    os.makedirs('saved_models', exist_ok=True)\n",
        "    os.makedirs('training_logs', exist_ok=True)\n",
        "    os.makedirs('generated_samples', exist_ok=True)\n",
        "\n",
        "    d_loss_values, g_loss_values = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, real_imgs in enumerate(dataloader):\n",
        "            real_imgs = real_imgs.to(device)\n",
        "            batch_size = real_imgs.size(0)\n",
        "\n",
        "            z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
        "            fake_imgs = G(z).detach()\n",
        "            real_validity = D(real_imgs)\n",
        "            fake_validity = D(fake_imgs)\n",
        "            gp = gradient_penalty(D, real_imgs, fake_imgs, device)\n",
        "\n",
        "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gp\n",
        "            optimizer_D.zero_grad()\n",
        "            d_loss.backward(retain_graph=True)\n",
        "            optimizer_D.step()\n",
        "\n",
        "            if i % 5 == 0:\n",
        "                z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
        "                fake_imgs = G(z)\n",
        "                fake_validity = D(fake_imgs)\n",
        "                g_loss = -torch.mean(fake_validity)\n",
        "                optimizer_G.zero_grad()\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "            d_loss_values.append(d_loss.item())\n",
        "            g_loss_values.append(g_loss.item())\n",
        "\n",
        "            if i % 50 == 0:\n",
        "                with torch.no_grad():\n",
        "                    sample_z = torch.randn(16, z_dim, 1, 1, device=device)\n",
        "                    generated_imgs = G(sample_z).cpu()\n",
        "                    grid = utils.make_grid(generated_imgs, nrow=4, normalize=True)\n",
        "                    utils.save_image(grid, f'generated_samples/epoch_{epoch+1}_step_{i}.png')\n",
        "\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(dataloader)}], \"\n",
        "                      f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "        torch.save(G.state_dict(), f\"saved_models/generator_epoch_{epoch+1}.pth\")\n",
        "        torch.save(D.state_dict(), f\"saved_models/discriminator_epoch_{epoch+1}.pth\")\n",
        "        print(f\"Models saved for epoch {epoch+1}\")\n",
        "\n",
        "    torch.save(G.state_dict(), f\"saved_models/generator.pth\")\n",
        "    torch.save(D.state_dict(), f\"saved_models/discriminator.pth\")\n",
        "    print(f\"Models saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKuYOafS8cWi"
      },
      "source": [
        "### 4. Evaluation: - Score: 10 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKVdICZv8cWi"
      },
      "outputs": [],
      "source": [
        "def save_real_images(dataloader, num_samples=1000, save_dir='real_images_subset'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    count = 0\n",
        "    for imgs in dataloader:\n",
        "        for img in imgs:\n",
        "            img = ((img + 1) / 2).clamp(0, 1)\n",
        "            utils.save_image(img, os.path.join(save_dir, f\"real_{count}.png\"))\n",
        "            count += 1\n",
        "            if count >= num_samples:\n",
        "                return\n",
        "\n",
        "os.makedirs('real_images_subset', exist_ok=True)\n",
        "if len(os.listdir('real_images_subset')) < 1000:\n",
        "    save_real_images(dataloader, num_samples=1000, save_dir='real_images_subset')\n",
        "    print(\"Saved 1000 real images for FID calculation.\")\n",
        "else:\n",
        "    print(\"Many Images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjCN1lIN8cWi"
      },
      "outputs": [],
      "source": [
        "def save_generated_images(G, z_dim=100, num_images=1000, batch_size=64, save_dir='generated_images_fid'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    G.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, num_images, batch_size):\n",
        "            current_batch_size = min(batch_size, num_images - i)\n",
        "            z = torch.randn(current_batch_size, z_dim, 1, 1, device=device)\n",
        "            fake_imgs = G(z).cpu()\n",
        "            fake_imgs = (fake_imgs * 0.5) + 0.5\n",
        "            for j in range(fake_imgs.size(0)):\n",
        "                utils.save_image(fake_imgs[j], os.path.join(save_dir, f\"fake_{i+j}.png\"))\n",
        "    print(f\"Saved {num_images} generated images to {save_dir}\")\n",
        "\n",
        "save_generated_images(G, z_dim=z_dim, num_images=1000, batch_size=64, save_dir='generated_images_fid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdTlAeUM8cWj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def compute_fid(real_dir, fake_dir):\n",
        "    paths = [real_dir, fake_dir]\n",
        "    fid_value = fid_score.calculate_fid_given_paths(\n",
        "        paths,\n",
        "        batch_size=128,\n",
        "        device=device,\n",
        "        dims=2048\n",
        "    )\n",
        "    print(f\"FID: {fid_value}\")\n",
        "\n",
        "compute_fid(real_dir='real_images_subset', fake_dir='generated_images_fid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BokCo87f8cWj"
      },
      "outputs": [],
      "source": [
        "def visualize_generated_images(G, z_dim=100, num_images=64):\n",
        "    G.eval()\n",
        "    with torch.no_grad():\n",
        "        sample_z = torch.randn(num_images, z_dim, 1, 1, device=device)\n",
        "        generated_imgs = G(sample_z).cpu()\n",
        "        generated_imgs = (generated_imgs * 0.5) + 0.5\n",
        "\n",
        "    plt.figure(figsize=(8,8))\n",
        "    grid = utils.make_grid(generated_imgs, nrow=8, normalize=False)\n",
        "    plt.imshow(grid.permute(1, 2, 0).numpy())\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_generated_images(G, z_dim=z_dim, num_images=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MHZkIIZ8cWj"
      },
      "outputs": [],
      "source": [
        "def compare_real_fake(real_dir='real_images_subset', fake_dir='generated_images_fid'):\n",
        "    real_imgs = sorted(glob.glob(os.path.join(real_dir, '*.png')))[:16]\n",
        "    fake_imgs = sorted(glob.glob(os.path.join(fake_dir, '*.png')))[:16]\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    for i in range(16):\n",
        "        plt.subplot(4, 8, i + 1)\n",
        "        img = Image.open(real_imgs[i]).convert(\"RGB\")\n",
        "        img = np.array(img)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        if i == 7:\n",
        "            plt.text(-10, 32, 'Real Images', fontsize=12, color='red')\n",
        "        plt.subplot(4, 8, i + 1 + 16)\n",
        "        img = Image.open(fake_imgs[i]).convert(\"RGB\")\n",
        "        img = np.array(img)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        if i == 7:\n",
        "            plt.text(-10, 32, 'Generated Images', fontsize=12, color='blue')\n",
        "    plt.show()\n",
        "\n",
        "compare_real_fake(real_dir='real_images_subset', fake_dir='generated_images_fid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUakNQL88cWj"
      },
      "source": [
        "### 5. Latent Space Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut57CF9P8cWj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "\n",
        "def slerp(val, low, high):\n",
        "    omega = torch.acos(torch.clamp(torch.dot(low.flatten(), high.flatten()) /\n",
        "                                   (torch.norm(low) * torch.norm(high)), -1, 1))\n",
        "    so = torch.sin(omega)\n",
        "    if so == 0:\n",
        "        return (low + high) / 2\n",
        "    return (torch.sin((1.0 - val) * omega) / so) * low + (torch.sin(val * omega) / so) * high\n",
        "\n",
        "def interpolate_latent_space_slerp(G, z_dim=100, steps=8, device='cpu'):\n",
        "    G.eval()\n",
        "    with torch.no_grad():\n",
        "        z1 = torch.randn(1, z_dim, 1, 1, device=device)\n",
        "        z2 = torch.randn(1, z_dim, 1, 1, device=device)\n",
        "        alphas = np.linspace(0, 1, steps)\n",
        "        interpolated_imgs = []\n",
        "\n",
        "        for alpha in alphas:\n",
        "            z = slerp(alpha, z1, z2)\n",
        "            img = G(z).cpu()\n",
        "            interpolated_imgs.append(img[0])\n",
        "        interpolated_imgs = torch.stack(interpolated_imgs)\n",
        "\n",
        "        grid = utils.make_grid(interpolated_imgs, nrow=steps, normalize=True)\n",
        "\n",
        "        plt.figure(figsize=(steps * 2, 2))\n",
        "        plt.imshow(grid.permute(1, 2, 0).numpy())\n",
        "        plt.title(\"Latent Space Slerp Interpolation\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "interpolate_latent_space_slerp(G, z_dim=z_dim, steps=8, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsg6fBQO8cWj"
      },
      "source": [
        "\n",
        "ì´ë²ˆ ê³¼ì œëŠ” GANì„ ì´ìš©í•´ CelebA ë°ì´í„°ì…‹ì„ í•™ìŠµ ì‹œí‚¤ê³ , ì´ë¥¼ í†µí•´ ê°€ìƒì˜ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ”ê²ƒì´ ëª©ì ìž…ë‹ˆë‹¤.\n",
        "Inference ë¶€ë¶„ì—ì„œëŠ” ì „ì²´ ê³¼ì •ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ê³¼ í•¨ê»˜, ëª¨ë¸ ì•„í‚¤í…ì²˜, í•™ìŠµ ê³¼ì •, í‰ê°€ ê²°ê³¼ ë“±ì„ ìž‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "## 1. ëª¨ë¸ ì•„í‚¤í…ì²˜\n",
        "\n",
        "### a. Generator\n",
        "GeneratorëŠ” ëžœë¤í•œ ìž ìž¬ ë²¡í„°\n",
        "ð‘§\n",
        "zë¥¼ ìž…ë ¥ìœ¼ë¡œ ë°›ì•„ ì‹¤ì œ ë°ì´í„° ë¶„í¬ì™€ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ì•„ëž˜ì™€ ê°™ì€ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤:\n",
        "\n",
        "ìž…ë ¥:\n",
        "\n",
        "ð‘§\n",
        "z: í¬ê¸° 100ì˜ ëžœë¤ ìž ìž¬ ë²¡í„°\n",
        "ìž…ë ¥ëœ\n",
        "ð‘§\n",
        "zëŠ” ë…¸ì´ì¦ˆë¥¼ í¬í•¨í•˜ë©°, ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "ConvTranspose2d ë ˆì´ì–´:\n",
        "\n",
        "ì—­í•©ì„±ê³±(Transpose Convolution): ìž ìž¬ ë²¡í„°ë¥¼ 4x4x256ì˜ í…ì„œë¡œ í™•ìž¥í•˜ê³ , ì´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì—…ìƒ˜í”Œë§í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ 64x64 í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "ì—…ìƒ˜í”Œë§ ê³¼ì •ì—ì„œ ì±„ë„ í¬ê¸°ë¥¼ ì ì°¨ ì¤„ì´ë©° ë‹¤ìŒê³¼ ê°™ì€ í•´ìƒë„ë¥¼ ë§Œë“­ë‹ˆë‹¤:\n",
        "4\n",
        "Ã—\n",
        "4\n",
        "4Ã—4 â†’\n",
        "8\n",
        "Ã—\n",
        "8\n",
        "8Ã—8 â†’\n",
        "16\n",
        "Ã—\n",
        "16\n",
        "16Ã—16 â†’\n",
        "32\n",
        "Ã—\n",
        "32\n",
        "32Ã—32 â†’\n",
        "64\n",
        "Ã—\n",
        "64\n",
        "64Ã—64.\n",
        "BatchNorm2d:\n",
        "\n",
        "ê° ConvTranspose2d ë ˆì´ì–´ ì´í›„ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©í•˜ì—¬ í•™ìŠµ ì•ˆì •ì„±ê³¼ ìˆ˜ë ´ ì†ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
        "í™œì„±í™” í•¨ìˆ˜:\n",
        "\n",
        "ì¤‘ê°„ ë ˆì´ì–´ì—ëŠ” ReLU í™œì„±í™” í•¨ìˆ˜ê°€ ì‚¬ìš©ë˜ì–´ ìŒìˆ˜ë¥¼ ì œê±°í•˜ê³  ë¹„ì„ í˜•ì„±ì„ ë„ìž…í•©ë‹ˆë‹¤.\n",
        "ìµœì¢… ë ˆì´ì–´ì—ëŠ” Tanh í™œì„±í™” í•¨ìˆ˜ê°€ ì‚¬ìš©ë˜ì–´ ì¶œë ¥ì„ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
        "ì¶œë ¥:\n",
        "\n",
        "RGB ì±„ë„ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë©° ì¶œë ¥ í¬ê¸°ëŠ”\n",
        "64\n",
        "Ã—\n",
        "64\n",
        "Ã—\n",
        "3\n",
        "64Ã—64Ã—3ìž…ë‹ˆë‹¤.\n",
        "ì—­ì „íŒŒ ê°€ëŠ¥:\n",
        "\n",
        "ConvTranspose2dì™€ BatchNorm2dì˜ ì¡°í•©ìœ¼ë¡œ GeneratorëŠ” ì—­ì „íŒŒê°€ íš¨ìœ¨ì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ë„ë¡ ì„¤ê³„ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.\n",
        "b. Discriminator\n",
        "DiscriminatorëŠ” Generatorê°€ ìƒì„±í•œ ê°€ì§œ ì´ë¯¸ì§€ì™€ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ êµ¬ë¶„í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ ì§„ìœ„ë¥¼ íŒë³„í•˜ë©°, ì•„ëž˜ì™€ ê°™ì€ êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤:\n",
        "\n",
        "ìž…ë ¥:\n",
        "\n",
        "ð‘¥\n",
        "x:\n",
        "64\n",
        "Ã—\n",
        "64\n",
        "Ã—\n",
        "3\n",
        "64Ã—64Ã—3 í¬ê¸°ì˜ RGB ì´ë¯¸ì§€\n",
        "ì‹¤ì œ ì´ë¯¸ì§€ì™€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ìž…ë ¥ë°›ìŠµë‹ˆë‹¤.\n",
        "Conv2d ë ˆì´ì–´:\n",
        "\n",
        "í•©ì„±ê³±: ìž…ë ¥ ì´ë¯¸ì§€ë¥¼ 64x64ì—ì„œ 32x32, 16x16, 8x8, 4x4ë¡œ ì ì§„ì ìœ¼ë¡œ ë‹¤ìš´ìƒ˜í”Œë§í•˜ë©°, ì±„ë„ ìˆ˜ëŠ” 32 â†’ 64 â†’ 128 â†’ 256ìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤.\n",
        "ë‹¤ìš´ìƒ˜í”Œë§ì„ í†µí•´ ê³ ìˆ˜ì¤€ì˜ íŠ¹ì§•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "BatchNorm2d:\n",
        "\n",
        "ê° Conv2d ë ˆì´ì–´ ì´í›„ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©í•˜ì—¬ í•™ìŠµ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
        "í™œì„±í™” í•¨ìˆ˜:\n",
        "\n",
        "LeakyReLU í™œì„±í™” í•¨ìˆ˜ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ìŒìˆ˜ ê¸°ìš¸ê¸°ë¥¼ ë„ìž…í•˜ì—¬ 0ì´ ì•„ë‹Œ ìž‘ì€ ê°’ì„ ë°˜í™˜í•˜ë©°, ì •ë³´ ì†ì‹¤ì„ ì¤„ì´ê³  ëª¨ë¸ì˜ í‘œí˜„ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
        "ìµœì¢… ë ˆì´ì–´:\n",
        "\n",
        "Conv2dë¡œ 4x4ì˜ í…ì„œë¥¼ 1x1ë¡œ ì¶•ì†Œí•˜ë©°, Sigmoid í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì¶œë ¥ì„ [0, 1] ë²”ìœ„ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
        "ì¶œë ¥ê°’ì€ ì´ë¯¸ì§€ê°€ ì‹¤ì œì¼ í™•ë¥ (0ì€ ê°€ì§œ, 1ì€ ì§„ì§œ)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        "ì¶œë ¥:\n",
        "\n",
        "ìŠ¤ì¹¼ë¼ ê°’(ì´ë¯¸ì§€ ì§„ìœ„ ì—¬ë¶€ í™•ë¥ )ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "ì¶”ê°€ ì„¤ëª…\n",
        "Generatorì™€ Discriminatorì˜ ê´€ê³„: GeneratorëŠ” Discriminatorë¥¼ ì†ì´ê¸° ìœ„í•´ ë” ì‹¤ì œì™€ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë ¤ê³  í•˜ë©°, DiscriminatorëŠ” ì´ ì´ë¯¸ì§€ë¥¼ êµ¬ë³„í•˜ë ¤ê³  í•™ìŠµí•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ê²½ìŸì (Adversarial)ì¸ í•™ìŠµ ê³¼ì •ìœ¼ë¡œ, ë‘ ëª¨ë¸ì´ ì„œë¡œ ë°œì „í•˜ë©´ì„œ ê· í˜•ì— ë„ë‹¬í•©ë‹ˆë‹¤.\n",
        "í™œì„±í™” í•¨ìˆ˜ ì„ íƒ:\n",
        "Generatorì˜ ìµœì¢… ë ˆì´ì–´ì—ì„œ TanhëŠ” ì¶œë ¥ê°’ì„ [-1, 1]ë¡œ ì •ê·œí™”í•˜ì—¬ ë°ì´í„° ë¶„í¬ì— ë§žê²Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.\n",
        "Discriminatorì˜ ìµœì¢… ë ˆì´ì–´ì—ì„œ SigmoidëŠ” í™•ë¥ ë¡œ ë³€í™˜í•´ ì§„ìœ„ ì—¬ë¶€ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "## 2. í•™ìŠµ ê³¼ì •\n",
        "\n",
        "### a. ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬\n",
        "\n",
        "1. **ë°ì´í„°ì…‹:** CelebA ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ì´ë¯¸ì§€ 200,000ìž¥ì„ í¬í•¨\n",
        "2. **ì „ì²˜ë¦¬:**\n",
        "- 2.1. **í¬ê¸° ì¡°ì •:** ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 64x64 í”½ì…€ë¡œ ë¦¬ì‚¬ì´ì¦ˆ\n",
        "- 2.2. **í…ì„œ ë³€í™˜:** ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜\n",
        "- 2.3. **ì •ê·œí™”:** í”½ì…€ ê°’ì„ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™” (\\( \\text{Normalize}((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \\))\n",
        "- 2.4. **DataLoader:** ë°°ì¹˜ í¬ê¸° 64, ì…”í”Œë§ ì ìš©í•˜ì—¬ ë°ì´í„° ë¡œë“œ\n",
        "\n",
        "### b. ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
        "\n",
        "3. **ì†ì‹¤ í•¨ìˆ˜:** Binary Cross Entropy Loss (BCE Loss)\n",
        "- 3.1. **Discriminator:** ì‹¤ì œ ì´ë¯¸ì§€ì™€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜\n",
        "- 3.2. **Generator:** Discriminatorë¥¼ ì†ì´ë ¤ëŠ” ëª©ì ìœ¼ë¡œ ì‚¬ìš©\n",
        "4. **ì˜µí‹°ë§ˆì´ì €:** Adam ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©\n",
        "- 4.1. **í•™ìŠµë¥ :** 0.0002\n",
        "- 4.2. **ë² íƒ€ ê°’:** (0.5, 0.999)\n",
        "\n",
        "### c. ë ˆì´ë¸” ìŠ¤ë¬´ë”©\n",
        "\n",
        "- 5.1. **ì§„ì§œ ë¼ë²¨:** 1 ëŒ€ì‹  0.9ë¡œ ì„¤ì •í•˜ì—¬ Discriminatorì˜ ìžì‹ ì´ ì§„ì§œ ì‚¬ëžŒì´ë¼ëŠ” ê²ƒì„ ì¸ì‹í•˜ëŠ”ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©\n",
        "- 5.2. **ê°€ì§œ ë¼ë²¨:** 0ìœ¼ë¡œ ì„¤ì •\n",
        "\n",
        "### d. í•™ìŠµ ë‹¨ê³„\n",
        "\n",
        "- **ì—í¬í¬ ìˆ˜:** 50\n",
        "- **í›ˆë ¨ ë‹¨ê³„:**\n",
        "  1. **Discriminator í•™ìŠµ:**\n",
        "     - ì‹¤ì œ ì´ë¯¸ì§€ì™€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ í†µí•´ Discriminatorì˜ ì†ì‹¤ ê³„ì‚°\n",
        "     - í•©ì‚°ëœ ì†ì‹¤ì„ ì—­ì „íŒŒí•˜ì—¬ Discriminatorì˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "  2. **Generator í•™ìŠµ:**\n",
        "     - ê°€ì§œ ì´ë¯¸ì§€ë¥¼ í†µí•´ Discriminatorì˜ ì¶œë ¥ì„ ë°›ì•„ Generatorì˜ ì†ì‹¤ ê³„ì‚° (ì§„ì§œë¡œ ì†ì´ë ¤ëŠ” ëª©í‘œ)\n",
        "     - ì†ì‹¤ì„ ì—­ì „íŒŒí•˜ì—¬ Generatorì˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "\n",
        "### e. ëª¨ë¸ ì €ìž¥\n",
        "\n",
        "- **ëª¨ë¸ ì €ìž¥:** ëª¨ë“  ì—í¬í¬ê°€ ì™„ë£Œëœ í›„, Generatorì™€ Discriminatorì˜ ê°€ì¤‘ì¹˜ë¥¼ ì €ìž¥í•˜ì—¬ ì¶”í›„ í‰ê°€ ë° ìž¬ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë„ë¡ í•¨\n",
        "\n",
        "## 3. ì•„ì‰¬ìš´ ì ê³¼ í–¥í›„ ê°œì„  ë°©í–¥\n",
        "\n",
        "1. **FID ì ìˆ˜**: í˜„ìž¬ FID ì ìˆ˜ëŠ” ì•„ì‰¬ìš´ ìˆ˜ì¤€ìž…ë‹ˆë‹¤. ì´ëŠ” ìƒì„±ëœ ì´ë¯¸ì§€ì˜ í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ì´ ì‹¤ì œ ì´ë¯¸ì§€ì™€ ìƒë‹¹í•œ ì°¨ì´ê°€ ìžˆìŒì„ ì˜ë¯¸í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ë” ë§Žì€ ì—í¬í¬ë¡œ í•™ìŠµí•˜ê³  ëª¨ë¸ êµ¬ì¡°ë¥¼ ê°œì„ í•˜ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìžˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "2. **í•™ìŠµ ì‹œê°„**: ì»´í“¨íŒ… ìžì›ì˜ í•œê³„ë¡œ ì¶©ë¶„í•œ ì—í¬í¬ ìˆ˜ë¡œ í•™ìŠµí•˜ì§€ ëª»í•œ ê²ƒì´ ì•„ì‰½ìŠµë‹ˆë‹¤. í˜„ìž¬ FID ì ìˆ˜ë¥¼ ë³´ë©´ ëª¨ë¸ì´ ì¶©ë¶„ížˆ ìˆ˜ë ´í•˜ì§€ ëª»í–ˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. GPU í™˜ê²½ì—ì„œ ë” ê¸´ ì‹œê°„ í•™ìŠµí•˜ë©´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìžˆì„ ê²ƒ ê°™ë‹¤ê³  ìƒê°ë©ë‹ˆë‹¤.\n",
        "\n",
        "3. **ì´ë¯¸ì§€ í’ˆì§ˆ**: ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ì´ ì•„ì§ ë§Žì´ íë¦¿í•˜ê³  ì„¸ë¶€ ë””í…Œì¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. StyleGANê³¼ ê°™ì€ ìµœì‹  ì•„í‚¤í…ì²˜ë¥¼ ì ìš©í•˜ë©´ ë” ì¢‹ì€ í’ˆì§ˆì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìžˆì„ ê²ƒ ê°™ë‹¤ê³  ìƒê°ë©ë‹ˆë‹¤."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}