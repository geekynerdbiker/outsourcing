{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "vRXQ5ogBmBe0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.applications import VGG16, InceptionV3, MobileNet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "vRXQ5ogBmBe0"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1_eC3K9z4GF",
        "outputId": "013d992e-26d7-4f08-e48b-ad51327546e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "n1_eC3K9z4GF"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "eRkQOGFtmiKo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive')"
      ],
      "id": "eRkQOGFtmiKo"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq textile_dataset1.zip"
      ],
      "metadata": {
        "id": "apX6JT8OgEAZ"
      },
      "id": "apX6JT8OgEAZ",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "l4ObbTQonuhK"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   horizontal_flip=True,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   fill_mode='nearest')"
      ],
      "id": "l4ObbTQonuhK"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IukILO9boSvs",
        "outputId": "089a5179-1fac-4062-8187-68c85943c3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1445 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory('./data/train',\n",
        "                                                    target_size=(150,150),\n",
        "                                                    batch_size=5,\n",
        "                                                    class_mode='binary')"
      ],
      "id": "IukILO9boSvs"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFChMG29nse8",
        "outputId": "0e592575-7e59-46db-a5dc-53e52bab3611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 870 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory('./data/test',\n",
        "                                                    target_size=(150,150),\n",
        "                                                    batch_size=5,\n",
        "                                                    class_mode='binary')\n"
      ],
      "id": "SFChMG29nse8"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYQR37J1X2D-",
        "outputId": "835c54d3-0ca1-49c9-fdb7-a693aad1cca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15239105 (58.13 MB)\n",
            "Trainable params: 524417 (2.00 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.8035\n",
            "Epoch 1: val_loss improved from inf to 0.37569, saving model to ./model/VGG16.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r289/289 [==============================] - 24s 79ms/step - loss: 0.4661 - accuracy: 0.8035 - val_loss: 0.3757 - val_accuracy: 0.8391\n",
            "Epoch 2/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.4204 - accuracy: 0.8249\n",
            "Epoch 2: val_loss improved from 0.37569 to 0.32374, saving model to ./model/VGG16.hdf5\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.4204 - accuracy: 0.8249 - val_loss: 0.3237 - val_accuracy: 0.8655\n",
            "Epoch 3/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3991 - accuracy: 0.8284\n",
            "Epoch 3: val_loss improved from 0.32374 to 0.28964, saving model to ./model/VGG16.hdf5\n",
            "289/289 [==============================] - 21s 71ms/step - loss: 0.3991 - accuracy: 0.8284 - val_loss: 0.2896 - val_accuracy: 0.8759\n",
            "Epoch 4/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8493\n",
            "Epoch 4: val_loss did not improve from 0.28964\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.3867 - accuracy: 0.8491 - val_loss: 0.3390 - val_accuracy: 0.8655\n",
            "Epoch 5/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8498\n",
            "Epoch 5: val_loss did not improve from 0.28964\n",
            "289/289 [==============================] - 19s 66ms/step - loss: 0.3749 - accuracy: 0.8498 - val_loss: 0.3060 - val_accuracy: 0.8690\n",
            "Epoch 6/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.8521\n",
            "Epoch 6: val_loss improved from 0.28964 to 0.27312, saving model to ./model/VGG16.hdf5\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.3672 - accuracy: 0.8519 - val_loss: 0.2731 - val_accuracy: 0.8816\n",
            "Epoch 7/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.8657\n",
            "Epoch 7: val_loss did not improve from 0.27312\n",
            "289/289 [==============================] - 20s 71ms/step - loss: 0.3522 - accuracy: 0.8657 - val_loss: 0.3445 - val_accuracy: 0.8563\n",
            "Epoch 8/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3573 - accuracy: 0.8569\n",
            "Epoch 8: val_loss improved from 0.27312 to 0.25428, saving model to ./model/VGG16.hdf5\n",
            "289/289 [==============================] - 20s 69ms/step - loss: 0.3586 - accuracy: 0.8567 - val_loss: 0.2543 - val_accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3611 - accuracy: 0.8576\n",
            "Epoch 9: val_loss improved from 0.25428 to 0.25235, saving model to ./model/VGG16.hdf5\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.3610 - accuracy: 0.8567 - val_loss: 0.2523 - val_accuracy: 0.8931\n",
            "Epoch 10/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.8720\n",
            "Epoch 10: val_loss did not improve from 0.25235\n",
            "289/289 [==============================] - 20s 69ms/step - loss: 0.3388 - accuracy: 0.8720 - val_loss: 0.2814 - val_accuracy: 0.8816\n",
            "Epoch 11/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3517 - accuracy: 0.8590\n",
            "Epoch 11: val_loss did not improve from 0.25235\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.3520 - accuracy: 0.8588 - val_loss: 0.3677 - val_accuracy: 0.8437\n",
            "Epoch 12/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.8637\n",
            "Epoch 12: val_loss did not improve from 0.25235\n",
            "289/289 [==============================] - 19s 66ms/step - loss: 0.3500 - accuracy: 0.8637 - val_loss: 0.3436 - val_accuracy: 0.8552\n",
            "Epoch 13/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.8685\n",
            "Epoch 13: val_loss did not improve from 0.25235\n",
            "289/289 [==============================] - 19s 67ms/step - loss: 0.3419 - accuracy: 0.8685 - val_loss: 0.3397 - val_accuracy: 0.8609\n",
            "Epoch 14/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.8616\n",
            "Epoch 14: val_loss did not improve from 0.25235\n",
            "289/289 [==============================] - 19s 66ms/step - loss: 0.3398 - accuracy: 0.8616 - val_loss: 0.2809 - val_accuracy: 0.8770\n",
            "174/174 [==============================] - 5s 28ms/step - loss: 0.2523 - accuracy: 0.8931\n",
            "Test accuracy: 0.8931034207344055\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15763521 (60.13 MB)\n",
            "Trainable params: 1048833 (4.00 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.4697 - accuracy: 0.8035\n",
            "Epoch 1: val_loss improved from inf to 0.31579, saving model to ./model/VGG16_2.hdf5\n",
            "289/289 [==============================] - 78s 266ms/step - loss: 0.4697 - accuracy: 0.8035 - val_loss: 0.3158 - val_accuracy: 0.8609\n",
            "Epoch 2/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.8229\n",
            "Epoch 2: val_loss did not improve from 0.31579\n",
            "289/289 [==============================] - 19s 66ms/step - loss: 0.4234 - accuracy: 0.8221 - val_loss: 0.4659 - val_accuracy: 0.8345\n",
            "Epoch 3/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3934 - accuracy: 0.8507\n",
            "Epoch 3: val_loss did not improve from 0.31579\n",
            "289/289 [==============================] - 20s 71ms/step - loss: 0.3946 - accuracy: 0.8505 - val_loss: 0.3334 - val_accuracy: 0.8609\n",
            "Epoch 4/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3963 - accuracy: 0.8458\n",
            "Epoch 4: val_loss improved from 0.31579 to 0.30917, saving model to ./model/VGG16_2.hdf5\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.3953 - accuracy: 0.8464 - val_loss: 0.3092 - val_accuracy: 0.8690\n",
            "Epoch 5/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8519\n",
            "Epoch 5: val_loss did not improve from 0.30917\n",
            "289/289 [==============================] - 20s 69ms/step - loss: 0.3725 - accuracy: 0.8519 - val_loss: 0.4364 - val_accuracy: 0.8391\n",
            "Epoch 6/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.8554\n",
            "Epoch 6: val_loss did not improve from 0.30917\n",
            "289/289 [==============================] - 19s 67ms/step - loss: 0.3702 - accuracy: 0.8554 - val_loss: 0.3734 - val_accuracy: 0.8552\n",
            "Epoch 7/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8581\n",
            "Epoch 7: val_loss improved from 0.30917 to 0.27807, saving model to ./model/VGG16_2.hdf5\n",
            "289/289 [==============================] - 21s 74ms/step - loss: 0.3594 - accuracy: 0.8581 - val_loss: 0.2781 - val_accuracy: 0.8759\n",
            "Epoch 8/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.8657\n",
            "Epoch 8: val_loss did not improve from 0.27807\n",
            "289/289 [==============================] - 19s 66ms/step - loss: 0.3504 - accuracy: 0.8657 - val_loss: 0.4693 - val_accuracy: 0.8241\n",
            "Epoch 9/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.8569\n",
            "Epoch 9: val_loss improved from 0.27807 to 0.23611, saving model to ./model/VGG16_2.hdf5\n",
            "289/289 [==============================] - 20s 69ms/step - loss: 0.3776 - accuracy: 0.8567 - val_loss: 0.2361 - val_accuracy: 0.9092\n",
            "Epoch 10/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.8637\n",
            "Epoch 10: val_loss did not improve from 0.23611\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.3424 - accuracy: 0.8637 - val_loss: 0.3783 - val_accuracy: 0.8517\n",
            "Epoch 11/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.8699\n",
            "Epoch 11: val_loss did not improve from 0.23611\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.3408 - accuracy: 0.8699 - val_loss: 0.2476 - val_accuracy: 0.8920\n",
            "Epoch 12/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8569\n",
            "Epoch 12: val_loss did not improve from 0.23611\n",
            "289/289 [==============================] - 19s 66ms/step - loss: 0.3519 - accuracy: 0.8567 - val_loss: 0.2815 - val_accuracy: 0.8747\n",
            "Epoch 13/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.8664\n",
            "Epoch 13: val_loss did not improve from 0.23611\n",
            "289/289 [==============================] - 20s 71ms/step - loss: 0.3379 - accuracy: 0.8664 - val_loss: 0.2731 - val_accuracy: 0.8759\n",
            "Epoch 14/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3283 - accuracy: 0.8694\n",
            "Epoch 14: val_loss did not improve from 0.23611\n",
            "289/289 [==============================] - 19s 66ms/step - loss: 0.3296 - accuracy: 0.8678 - val_loss: 0.3557 - val_accuracy: 0.8529\n",
            "174/174 [==============================] - 4s 24ms/step - loss: 0.2361 - accuracy: 0.9092\n",
            "Test accuracy: 0.9091954231262207\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_16 (InputLayer)       [(None, 150, 150, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_470 (Conv2D)         (None, 74, 74, 32)           864       ['input_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_470 (B  (None, 74, 74, 32)           96        ['conv2d_470[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_470 (Activation  (None, 74, 74, 32)           0         ['batch_normalization_470[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_471 (Conv2D)         (None, 72, 72, 32)           9216      ['activation_470[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_471 (B  (None, 72, 72, 32)           96        ['conv2d_471[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_471 (Activation  (None, 72, 72, 32)           0         ['batch_normalization_471[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_472 (Conv2D)         (None, 72, 72, 64)           18432     ['activation_471[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_472 (B  (None, 72, 72, 64)           192       ['conv2d_472[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_472 (Activation  (None, 72, 72, 64)           0         ['batch_normalization_472[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_20 (MaxPooli  (None, 35, 35, 64)           0         ['activation_472[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_473 (Conv2D)         (None, 35, 35, 80)           5120      ['max_pooling2d_20[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_473 (B  (None, 35, 35, 80)           240       ['conv2d_473[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_473 (Activation  (None, 35, 35, 80)           0         ['batch_normalization_473[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_474 (Conv2D)         (None, 33, 33, 192)          138240    ['activation_473[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_474 (B  (None, 33, 33, 192)          576       ['conv2d_474[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_474 (Activation  (None, 33, 33, 192)          0         ['batch_normalization_474[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_21 (MaxPooli  (None, 16, 16, 192)          0         ['activation_474[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_478 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_478 (B  (None, 16, 16, 64)           192       ['conv2d_478[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_478 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_478[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_476 (Conv2D)         (None, 16, 16, 48)           9216      ['max_pooling2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_479 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_478[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_476 (B  (None, 16, 16, 48)           144       ['conv2d_476[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_479 (B  (None, 16, 16, 96)           288       ['conv2d_479[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_476 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_476[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_479 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_479[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_45 (Aver  (None, 16, 16, 192)          0         ['max_pooling2d_21[0][0]']    \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_475 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_477 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_476[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_480 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_479[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_481 (Conv2D)         (None, 16, 16, 32)           6144      ['average_pooling2d_45[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_475 (B  (None, 16, 16, 64)           192       ['conv2d_475[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_477 (B  (None, 16, 16, 64)           192       ['conv2d_477[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_480 (B  (None, 16, 16, 96)           288       ['conv2d_480[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_481 (B  (None, 16, 16, 32)           96        ['conv2d_481[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_475 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_475[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_477 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_477[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_480 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_480[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_481 (Activation  (None, 16, 16, 32)           0         ['batch_normalization_481[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_475[0][0]',      \n",
            "                                                                     'activation_477[0][0]',      \n",
            "                                                                     'activation_480[0][0]',      \n",
            "                                                                     'activation_481[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_485 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_485 (B  (None, 16, 16, 64)           192       ['conv2d_485[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_485 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_485[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_483 (Conv2D)         (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_486 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_485[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_483 (B  (None, 16, 16, 48)           144       ['conv2d_483[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_486 (B  (None, 16, 16, 96)           288       ['conv2d_486[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_483 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_483[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_486 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_486[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_46 (Aver  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_482 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_484 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_483[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_487 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_486[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_488 (Conv2D)         (None, 16, 16, 64)           16384     ['average_pooling2d_46[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_482 (B  (None, 16, 16, 64)           192       ['conv2d_482[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_484 (B  (None, 16, 16, 64)           192       ['conv2d_484[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_487 (B  (None, 16, 16, 96)           288       ['conv2d_487[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_488 (B  (None, 16, 16, 64)           192       ['conv2d_488[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_482 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_482[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_484 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_484[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_487 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_487[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_488 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_488[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_482[0][0]',      \n",
            "                                                                     'activation_484[0][0]',      \n",
            "                                                                     'activation_487[0][0]',      \n",
            "                                                                     'activation_488[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_492 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_492 (B  (None, 16, 16, 64)           192       ['conv2d_492[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_492 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_492[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_490 (Conv2D)         (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_493 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_492[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_490 (B  (None, 16, 16, 48)           144       ['conv2d_490[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_493 (B  (None, 16, 16, 96)           288       ['conv2d_493[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_490 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_490[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_493 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_493[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_47 (Aver  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_489 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_491 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_490[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_494 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_493[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_495 (Conv2D)         (None, 16, 16, 64)           18432     ['average_pooling2d_47[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_489 (B  (None, 16, 16, 64)           192       ['conv2d_489[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_491 (B  (None, 16, 16, 64)           192       ['conv2d_491[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_494 (B  (None, 16, 16, 96)           288       ['conv2d_494[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_495 (B  (None, 16, 16, 64)           192       ['conv2d_495[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_489 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_489[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_491 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_491[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_494 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_494[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_495 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_495[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_489[0][0]',      \n",
            "                                                                     'activation_491[0][0]',      \n",
            "                                                                     'activation_494[0][0]',      \n",
            "                                                                     'activation_495[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_497 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_497 (B  (None, 16, 16, 64)           192       ['conv2d_497[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_497 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_497[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_498 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_497[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_498 (B  (None, 16, 16, 96)           288       ['conv2d_498[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_498 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_498[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_496 (Conv2D)         (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_499 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_498[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_496 (B  (None, 7, 7, 384)            1152      ['conv2d_496[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_499 (B  (None, 7, 7, 96)             288       ['conv2d_499[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_496 (Activation  (None, 7, 7, 384)            0         ['batch_normalization_496[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_499 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_499[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_22 (MaxPooli  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_496[0][0]',      \n",
            "                                                                     'activation_499[0][0]',      \n",
            "                                                                     'max_pooling2d_22[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_504 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_504 (B  (None, 7, 7, 128)            384       ['conv2d_504[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_504 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_504[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_505 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_504[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_505 (B  (None, 7, 7, 128)            384       ['conv2d_505[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_505 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_505[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_501 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_506 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_505[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_501 (B  (None, 7, 7, 128)            384       ['conv2d_501[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_506 (B  (None, 7, 7, 128)            384       ['conv2d_506[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_501 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_501[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_506 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_506[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_502 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_501[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_507 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_506[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_502 (B  (None, 7, 7, 128)            384       ['conv2d_502[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_507 (B  (None, 7, 7, 128)            384       ['conv2d_507[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_502 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_502[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_507 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_507[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_48 (Aver  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_500 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_503 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_502[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_508 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_507[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_509 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_48[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_500 (B  (None, 7, 7, 192)            576       ['conv2d_500[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_503 (B  (None, 7, 7, 192)            576       ['conv2d_503[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_508 (B  (None, 7, 7, 192)            576       ['conv2d_508[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_509 (B  (None, 7, 7, 192)            576       ['conv2d_509[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_500 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_500[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_503 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_503[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_508 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_508[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_509 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_509[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_500[0][0]',      \n",
            "                                                                     'activation_503[0][0]',      \n",
            "                                                                     'activation_508[0][0]',      \n",
            "                                                                     'activation_509[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_514 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_514 (B  (None, 7, 7, 160)            480       ['conv2d_514[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_514 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_514[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_515 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_514[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_515 (B  (None, 7, 7, 160)            480       ['conv2d_515[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_515 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_515[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_511 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_516 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_515[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_511 (B  (None, 7, 7, 160)            480       ['conv2d_511[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_516 (B  (None, 7, 7, 160)            480       ['conv2d_516[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_511 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_511[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_516 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_516[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_512 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_511[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_517 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_516[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_512 (B  (None, 7, 7, 160)            480       ['conv2d_512[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_517 (B  (None, 7, 7, 160)            480       ['conv2d_517[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_512 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_512[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_517 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_517[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_49 (Aver  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_510 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_513 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_512[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_518 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_517[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_519 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_49[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_510 (B  (None, 7, 7, 192)            576       ['conv2d_510[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_513 (B  (None, 7, 7, 192)            576       ['conv2d_513[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_518 (B  (None, 7, 7, 192)            576       ['conv2d_518[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_519 (B  (None, 7, 7, 192)            576       ['conv2d_519[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_510 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_510[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_513 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_513[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_518 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_518[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_519 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_519[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_510[0][0]',      \n",
            "                                                                     'activation_513[0][0]',      \n",
            "                                                                     'activation_518[0][0]',      \n",
            "                                                                     'activation_519[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_524 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_524 (B  (None, 7, 7, 160)            480       ['conv2d_524[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_524 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_524[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_525 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_524[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_525 (B  (None, 7, 7, 160)            480       ['conv2d_525[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_525 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_525[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_521 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_526 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_525[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_521 (B  (None, 7, 7, 160)            480       ['conv2d_521[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_526 (B  (None, 7, 7, 160)            480       ['conv2d_526[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_521 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_521[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_526 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_526[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_522 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_521[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_527 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_526[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_522 (B  (None, 7, 7, 160)            480       ['conv2d_522[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_527 (B  (None, 7, 7, 160)            480       ['conv2d_527[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_522 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_522[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_527 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_527[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_50 (Aver  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_520 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_523 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_522[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_528 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_527[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_529 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_50[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_520 (B  (None, 7, 7, 192)            576       ['conv2d_520[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_523 (B  (None, 7, 7, 192)            576       ['conv2d_523[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_528 (B  (None, 7, 7, 192)            576       ['conv2d_528[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_529 (B  (None, 7, 7, 192)            576       ['conv2d_529[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_520 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_520[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_523 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_523[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_528 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_528[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_529 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_529[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_520[0][0]',      \n",
            "                                                                     'activation_523[0][0]',      \n",
            "                                                                     'activation_528[0][0]',      \n",
            "                                                                     'activation_529[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_534 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_534 (B  (None, 7, 7, 192)            576       ['conv2d_534[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_534 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_534[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_535 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_534[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_535 (B  (None, 7, 7, 192)            576       ['conv2d_535[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_535 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_535[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_531 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_536 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_535[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_531 (B  (None, 7, 7, 192)            576       ['conv2d_531[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_536 (B  (None, 7, 7, 192)            576       ['conv2d_536[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_531 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_531[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_536 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_536[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_532 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_531[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_537 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_536[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_532 (B  (None, 7, 7, 192)            576       ['conv2d_532[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_537 (B  (None, 7, 7, 192)            576       ['conv2d_537[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_532 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_532[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_537 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_537[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_51 (Aver  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_530 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_533 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_532[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_538 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_537[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_539 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_51[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_530 (B  (None, 7, 7, 192)            576       ['conv2d_530[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_533 (B  (None, 7, 7, 192)            576       ['conv2d_533[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_538 (B  (None, 7, 7, 192)            576       ['conv2d_538[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_539 (B  (None, 7, 7, 192)            576       ['conv2d_539[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_530 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_530[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_533 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_533[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_538 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_538[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_539 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_539[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_530[0][0]',      \n",
            "                                                                     'activation_533[0][0]',      \n",
            "                                                                     'activation_538[0][0]',      \n",
            "                                                                     'activation_539[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_542 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_542 (B  (None, 7, 7, 192)            576       ['conv2d_542[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_542 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_542[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_543 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_542[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_543 (B  (None, 7, 7, 192)            576       ['conv2d_543[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_543 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_543[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_540 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_544 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_543[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_540 (B  (None, 7, 7, 192)            576       ['conv2d_540[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_544 (B  (None, 7, 7, 192)            576       ['conv2d_544[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_540 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_540[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_544 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_544[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_541 (Conv2D)         (None, 3, 3, 320)            552960    ['activation_540[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_545 (Conv2D)         (None, 3, 3, 192)            331776    ['activation_544[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_541 (B  (None, 3, 3, 320)            960       ['conv2d_541[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_545 (B  (None, 3, 3, 192)            576       ['conv2d_545[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_541 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_541[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_545 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_545[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_23 (MaxPooli  (None, 3, 3, 768)            0         ['mixed7[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 3, 3, 1280)           0         ['activation_541[0][0]',      \n",
            "                                                                     'activation_545[0][0]',      \n",
            "                                                                     'max_pooling2d_23[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_550 (Conv2D)         (None, 3, 3, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_550 (B  (None, 3, 3, 448)            1344      ['conv2d_550[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_550 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_550[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_547 (Conv2D)         (None, 3, 3, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_551 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_550[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_547 (B  (None, 3, 3, 384)            1152      ['conv2d_547[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_551 (B  (None, 3, 3, 384)            1152      ['conv2d_551[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_547 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_547[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_551 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_551[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_548 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_547[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_549 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_547[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_552 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_551[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_553 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_551[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_52 (Aver  (None, 3, 3, 1280)           0         ['mixed8[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_546 (Conv2D)         (None, 3, 3, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_548 (B  (None, 3, 3, 384)            1152      ['conv2d_548[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_549 (B  (None, 3, 3, 384)            1152      ['conv2d_549[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_552 (B  (None, 3, 3, 384)            1152      ['conv2d_552[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_553 (B  (None, 3, 3, 384)            1152      ['conv2d_553[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_554 (Conv2D)         (None, 3, 3, 192)            245760    ['average_pooling2d_52[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_546 (B  (None, 3, 3, 320)            960       ['conv2d_546[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_548 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_548[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_549 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_549[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_552 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_552[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_553 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_553[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_554 (B  (None, 3, 3, 192)            576       ['conv2d_554[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_546 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_546[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 3, 3, 768)            0         ['activation_548[0][0]',      \n",
            "                                                                     'activation_549[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 3, 3, 768)            0         ['activation_552[0][0]',      \n",
            " e)                                                                  'activation_553[0][0]']      \n",
            "                                                                                                  \n",
            " activation_554 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_554[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 3, 3, 2048)           0         ['activation_546[0][0]',      \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate_10[0][0]',      \n",
            "                                                                     'activation_554[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_559 (Conv2D)         (None, 3, 3, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_559 (B  (None, 3, 3, 448)            1344      ['conv2d_559[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_559 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_559[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_556 (Conv2D)         (None, 3, 3, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_560 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_559[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_556 (B  (None, 3, 3, 384)            1152      ['conv2d_556[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_560 (B  (None, 3, 3, 384)            1152      ['conv2d_560[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_556 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_556[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_560 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_560[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_557 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_556[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_558 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_556[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_561 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_560[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_562 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_560[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_53 (Aver  (None, 3, 3, 2048)           0         ['mixed9[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_555 (Conv2D)         (None, 3, 3, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_557 (B  (None, 3, 3, 384)            1152      ['conv2d_557[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_558 (B  (None, 3, 3, 384)            1152      ['conv2d_558[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_561 (B  (None, 3, 3, 384)            1152      ['conv2d_561[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_562 (B  (None, 3, 3, 384)            1152      ['conv2d_562[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_563 (Conv2D)         (None, 3, 3, 192)            393216    ['average_pooling2d_53[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_555 (B  (None, 3, 3, 320)            960       ['conv2d_555[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_557 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_557[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_558 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_558[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_561 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_561[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_562 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_562[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_563 (B  (None, 3, 3, 192)            576       ['conv2d_563[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_555 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_555[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 3, 3, 768)            0         ['activation_557[0][0]',      \n",
            "                                                                     'activation_558[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 3, 3, 768)            0         ['activation_561[0][0]',      \n",
            " e)                                                                  'activation_562[0][0]']      \n",
            "                                                                                                  \n",
            " activation_563 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_563[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 3, 3, 2048)           0         ['activation_555[0][0]',      \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_11[0][0]',      \n",
            "                                                                     'activation_563[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21802784 (83.17 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 21802784 (83.17 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 3, 3, 2048)        21802784  \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 64)                1179712   \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22982561 (87.67 MB)\n",
            "Trainable params: 1179777 (4.50 MB)\n",
            "Non-trainable params: 21802784 (83.17 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.8069\n",
            "Epoch 1: val_loss improved from inf to 0.45427, saving model to ./model/InceptionV3.hdf5\n",
            "289/289 [==============================] - 32s 94ms/step - loss: 0.4338 - accuracy: 0.8069 - val_loss: 0.4543 - val_accuracy: 0.8138\n",
            "Epoch 2/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3555 - accuracy: 0.8457\n",
            "Epoch 2: val_loss improved from 0.45427 to 0.31683, saving model to ./model/InceptionV3.hdf5\n",
            "289/289 [==============================] - 25s 87ms/step - loss: 0.3555 - accuracy: 0.8457 - val_loss: 0.3168 - val_accuracy: 0.8586\n",
            "Epoch 3/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.8526\n",
            "Epoch 3: val_loss improved from 0.31683 to 0.28813, saving model to ./model/InceptionV3.hdf5\n",
            "289/289 [==============================] - 23s 81ms/step - loss: 0.3273 - accuracy: 0.8526 - val_loss: 0.2881 - val_accuracy: 0.8667\n",
            "Epoch 4/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.8609\n",
            "Epoch 4: val_loss did not improve from 0.28813\n",
            "289/289 [==============================] - 24s 83ms/step - loss: 0.3303 - accuracy: 0.8609 - val_loss: 0.3788 - val_accuracy: 0.8184\n",
            "Epoch 5/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.8754\n",
            "Epoch 5: val_loss did not improve from 0.28813\n",
            "289/289 [==============================] - 23s 78ms/step - loss: 0.3009 - accuracy: 0.8754 - val_loss: 0.3063 - val_accuracy: 0.8471\n",
            "Epoch 6/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.8761\n",
            "Epoch 6: val_loss improved from 0.28813 to 0.28388, saving model to ./model/InceptionV3.hdf5\n",
            "289/289 [==============================] - 24s 85ms/step - loss: 0.2930 - accuracy: 0.8761 - val_loss: 0.2839 - val_accuracy: 0.8586\n",
            "Epoch 7/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.8782\n",
            "Epoch 7: val_loss did not improve from 0.28388\n",
            "289/289 [==============================] - 24s 81ms/step - loss: 0.2835 - accuracy: 0.8782 - val_loss: 0.3025 - val_accuracy: 0.8655\n",
            "Epoch 8/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.8844\n",
            "Epoch 8: val_loss improved from 0.28388 to 0.24048, saving model to ./model/InceptionV3.hdf5\n",
            "289/289 [==============================] - 25s 87ms/step - loss: 0.2683 - accuracy: 0.8844 - val_loss: 0.2405 - val_accuracy: 0.8908\n",
            "Epoch 9/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.8837\n",
            "Epoch 9: val_loss did not improve from 0.24048\n",
            "289/289 [==============================] - 22s 75ms/step - loss: 0.2600 - accuracy: 0.8837 - val_loss: 0.2637 - val_accuracy: 0.8828\n",
            "Epoch 10/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.8948\n",
            "Epoch 10: val_loss did not improve from 0.24048\n",
            "289/289 [==============================] - 23s 80ms/step - loss: 0.2609 - accuracy: 0.8948 - val_loss: 0.2483 - val_accuracy: 0.8816\n",
            "Epoch 11/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.8913\n",
            "Epoch 11: val_loss did not improve from 0.24048\n",
            "289/289 [==============================] - 23s 81ms/step - loss: 0.2637 - accuracy: 0.8913 - val_loss: 0.2906 - val_accuracy: 0.8575\n",
            "Epoch 12/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2734 - accuracy: 0.8858\n",
            "Epoch 12: val_loss did not improve from 0.24048\n",
            "289/289 [==============================] - 23s 78ms/step - loss: 0.2734 - accuracy: 0.8858 - val_loss: 0.3232 - val_accuracy: 0.8494\n",
            "Epoch 13/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.8824\n",
            "Epoch 13: val_loss improved from 0.24048 to 0.19368, saving model to ./model/InceptionV3.hdf5\n",
            "289/289 [==============================] - 25s 86ms/step - loss: 0.2619 - accuracy: 0.8824 - val_loss: 0.1937 - val_accuracy: 0.9103\n",
            "Epoch 14/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.8948\n",
            "Epoch 14: val_loss did not improve from 0.19368\n",
            "289/289 [==============================] - 22s 77ms/step - loss: 0.2378 - accuracy: 0.8948 - val_loss: 0.2020 - val_accuracy: 0.9057\n",
            "Epoch 15/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.8913\n",
            "Epoch 15: val_loss improved from 0.19368 to 0.18797, saving model to ./model/InceptionV3.hdf5\n",
            "289/289 [==============================] - 24s 82ms/step - loss: 0.2425 - accuracy: 0.8913 - val_loss: 0.1880 - val_accuracy: 0.9241\n",
            "Epoch 16/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.8969\n",
            "Epoch 16: val_loss did not improve from 0.18797\n",
            "289/289 [==============================] - 24s 83ms/step - loss: 0.2418 - accuracy: 0.8969 - val_loss: 0.2521 - val_accuracy: 0.8885\n",
            "Epoch 17/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.8927\n",
            "Epoch 17: val_loss did not improve from 0.18797\n",
            "289/289 [==============================] - 24s 82ms/step - loss: 0.2378 - accuracy: 0.8927 - val_loss: 0.3361 - val_accuracy: 0.8575\n",
            "Epoch 18/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.8962\n",
            "Epoch 18: val_loss did not improve from 0.18797\n",
            "289/289 [==============================] - 22s 76ms/step - loss: 0.2440 - accuracy: 0.8962 - val_loss: 0.3040 - val_accuracy: 0.8690\n",
            "Epoch 19/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.9045\n",
            "Epoch 19: val_loss did not improve from 0.18797\n",
            "289/289 [==============================] - 23s 81ms/step - loss: 0.2292 - accuracy: 0.9045 - val_loss: 0.2101 - val_accuracy: 0.9011\n",
            "Epoch 20/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.9024\n",
            "Epoch 20: val_loss did not improve from 0.18797\n",
            "289/289 [==============================] - 22s 75ms/step - loss: 0.2270 - accuracy: 0.9024 - val_loss: 0.3194 - val_accuracy: 0.8506\n",
            "174/174 [==============================] - 6s 27ms/step - loss: 0.1880 - accuracy: 0.9241\n",
            "Test accuracy: 0.9241379499435425\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 3, 3, 2048)        21802784  \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 128)               2359424   \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24162337 (92.17 MB)\n",
            "Trainable params: 2359553 (9.00 MB)\n",
            "Non-trainable params: 21802784 (83.17 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.8048\n",
            "Epoch 1: val_loss improved from inf to 0.53880, saving model to ./model/InceptionV3_2.hdf5\n",
            "289/289 [==============================] - 34s 103ms/step - loss: 0.4467 - accuracy: 0.8048 - val_loss: 0.5388 - val_accuracy: 0.8115\n",
            "Epoch 2/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3928 - accuracy: 0.8367\n",
            "Epoch 2: val_loss improved from 0.53880 to 0.26788, saving model to ./model/InceptionV3_2.hdf5\n",
            "289/289 [==============================] - 25s 86ms/step - loss: 0.3928 - accuracy: 0.8367 - val_loss: 0.2679 - val_accuracy: 0.8724\n",
            "Epoch 3/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.8637\n",
            "Epoch 3: val_loss did not improve from 0.26788\n",
            "289/289 [==============================] - 22s 76ms/step - loss: 0.3231 - accuracy: 0.8637 - val_loss: 0.4725 - val_accuracy: 0.7759\n",
            "Epoch 4/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.8747\n",
            "Epoch 4: val_loss did not improve from 0.26788\n",
            "289/289 [==============================] - 23s 81ms/step - loss: 0.3035 - accuracy: 0.8747 - val_loss: 0.3246 - val_accuracy: 0.8678\n",
            "Epoch 5/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.8664\n",
            "Epoch 5: val_loss did not improve from 0.26788\n",
            "289/289 [==============================] - 24s 82ms/step - loss: 0.3115 - accuracy: 0.8664 - val_loss: 0.2780 - val_accuracy: 0.8632\n",
            "Epoch 6/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.8900\n",
            "Epoch 6: val_loss did not improve from 0.26788\n",
            "289/289 [==============================] - 24s 83ms/step - loss: 0.2944 - accuracy: 0.8900 - val_loss: 0.3020 - val_accuracy: 0.8724\n",
            "Epoch 7/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.8824\n",
            "Epoch 7: val_loss did not improve from 0.26788\n",
            "289/289 [==============================] - 23s 79ms/step - loss: 0.3112 - accuracy: 0.8824 - val_loss: 0.4365 - val_accuracy: 0.7989\n",
            "174/174 [==============================] - 7s 30ms/step - loss: 0.2679 - accuracy: 0.8724\n",
            "Test accuracy: 0.8724138140678406\n",
            "Model: \"mobilenet_1.00_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 75, 75, 32)        864       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizati  (None, 75, 75, 32)        128       \n",
            " on)                                                             \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 75, 75, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D  (None, 75, 75, 32)        288       \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormali  (None, 75, 75, 32)        128       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 75, 75, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 75, 75, 64)        2048      \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormali  (None, 75, 75, 64)        256       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 76, 76, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D  (None, 37, 37, 64)        576       \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormali  (None, 37, 37, 64)        256       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 37, 37, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 37, 37, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormali  (None, 37, 37, 128)       512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D  (None, 37, 37, 128)       1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormali  (None, 37, 37, 128)       512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 37, 37, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormali  (None, 37, 37, 128)       512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 38, 38, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D  (None, 18, 18, 128)       1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormali  (None, 18, 18, 128)       512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 18, 18, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 18, 18, 256)       32768     \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormali  (None, 18, 18, 256)       1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D  (None, 18, 18, 256)       2304      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormali  (None, 18, 18, 256)       1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 18, 18, 256)       65536     \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormali  (None, 18, 18, 256)       1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 19, 19, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D  (None, 9, 9, 256)         2304      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormali  (None, 9, 9, 256)         1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 9, 9, 256)         0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 9, 9, 512)         131072    \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormali  (None, 9, 9, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D  (None, 9, 9, 512)         4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormali  (None, 9, 9, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 9, 9, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormali  (None, 9, 9, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D  (None, 9, 9, 512)         4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormali  (None, 9, 9, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 9, 9, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormali  (None, 9, 9, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D  (None, 9, 9, 512)         4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormali  (None, 9, 9, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 9, 9, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormali  (None, 9, 9, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2  (None, 9, 9, 512)         4608      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormal  (None, 9, 9, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 9, 9, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormal  (None, 9, 9, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2  (None, 9, 9, 512)         4608      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormal  (None, 9, 9, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 9, 9, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormal  (None, 9, 9, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D  (None, 10, 10, 512)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2  (None, 4, 4, 512)         4608      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormal  (None, 4, 4, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 4, 4, 1024)        524288    \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormal  (None, 4, 4, 1024)        4096      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 4, 4, 1024)        0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2  (None, 4, 4, 1024)        9216      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormal  (None, 4, 4, 1024)        4096      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 4, 4, 1024)        0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 4, 4, 1024)        1048576   \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormal  (None, 4, 4, 1024)        4096      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 4, 4, 1024)        0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3228864 (12.32 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 3228864 (12.32 MB)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenet_1.00_224 (Functi  (None, 4, 4, 1024)        3228864   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 64)                1048640   \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4277569 (16.32 MB)\n",
            "Trainable params: 1048705 (4.00 MB)\n",
            "Non-trainable params: 3228864 (12.32 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.8000\n",
            "Epoch 1: val_loss improved from inf to 0.36431, saving model to ./model/MobileNet.hdf5\n",
            "289/289 [==============================] - 23s 72ms/step - loss: 0.4853 - accuracy: 0.8000 - val_loss: 0.3643 - val_accuracy: 0.8655\n",
            "Epoch 2/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8388\n",
            "Epoch 2: val_loss improved from 0.36431 to 0.29593, saving model to ./model/MobileNet.hdf5\n",
            "289/289 [==============================] - 21s 74ms/step - loss: 0.3911 - accuracy: 0.8388 - val_loss: 0.2959 - val_accuracy: 0.8782\n",
            "Epoch 3/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3650 - accuracy: 0.8554\n",
            "Epoch 3: val_loss did not improve from 0.29593\n",
            "289/289 [==============================] - 22s 75ms/step - loss: 0.3650 - accuracy: 0.8554 - val_loss: 0.3169 - val_accuracy: 0.8782\n",
            "Epoch 4/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8616\n",
            "Epoch 4: val_loss improved from 0.29593 to 0.27714, saving model to ./model/MobileNet.hdf5\n",
            "289/289 [==============================] - 20s 69ms/step - loss: 0.3455 - accuracy: 0.8616 - val_loss: 0.2771 - val_accuracy: 0.8851\n",
            "Epoch 5/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8657\n",
            "Epoch 5: val_loss improved from 0.27714 to 0.27354, saving model to ./model/MobileNet.hdf5\n",
            "289/289 [==============================] - 21s 71ms/step - loss: 0.3305 - accuracy: 0.8657 - val_loss: 0.2735 - val_accuracy: 0.8966\n",
            "Epoch 6/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.8830\n",
            "Epoch 6: val_loss did not improve from 0.27354\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.3015 - accuracy: 0.8830 - val_loss: 0.3108 - val_accuracy: 0.8908\n",
            "Epoch 7/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.8736\n",
            "Epoch 7: val_loss improved from 0.27354 to 0.22212, saving model to ./model/MobileNet.hdf5\n",
            "289/289 [==============================] - 23s 78ms/step - loss: 0.3002 - accuracy: 0.8734 - val_loss: 0.2221 - val_accuracy: 0.9172\n",
            "Epoch 8/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3073 - accuracy: 0.8632\n",
            "Epoch 8: val_loss did not improve from 0.22212\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.3062 - accuracy: 0.8637 - val_loss: 0.2390 - val_accuracy: 0.9161\n",
            "Epoch 9/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.8817\n",
            "Epoch 9: val_loss did not improve from 0.22212\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.3047 - accuracy: 0.8817 - val_loss: 0.2820 - val_accuracy: 0.8816\n",
            "Epoch 10/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 0.8817\n",
            "Epoch 10: val_loss did not improve from 0.22212\n",
            "289/289 [==============================] - 24s 81ms/step - loss: 0.2913 - accuracy: 0.8817 - val_loss: 0.2703 - val_accuracy: 0.8954\n",
            "Epoch 11/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.8734\n",
            "Epoch 11: val_loss did not improve from 0.22212\n",
            "289/289 [==============================] - 19s 67ms/step - loss: 0.2894 - accuracy: 0.8734 - val_loss: 0.2539 - val_accuracy: 0.9034\n",
            "Epoch 12/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.2803 - accuracy: 0.8833\n",
            "Epoch 12: val_loss did not improve from 0.22212\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.2801 - accuracy: 0.8830 - val_loss: 0.2500 - val_accuracy: 0.9046\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.2221 - accuracy: 0.9172\n",
            "Test accuracy: 0.9172413945198059\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenet_1.00_224 (Functi  (None, 4, 4, 1024)        3228864   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 128)               2097280   \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5326273 (20.32 MB)\n",
            "Trainable params: 2097409 (8.00 MB)\n",
            "Non-trainable params: 3228864 (12.32 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.4793 - accuracy: 0.8042\n",
            "Epoch 1: val_loss improved from inf to 0.34281, saving model to ./model/MobileNet_2.hdf5\n",
            "289/289 [==============================] - 23s 73ms/step - loss: 0.4793 - accuracy: 0.8042 - val_loss: 0.3428 - val_accuracy: 0.8839\n",
            "Epoch 2/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.8304\n",
            "Epoch 2: val_loss improved from 0.34281 to 0.32195, saving model to ./model/MobileNet_2.hdf5\n",
            "289/289 [==============================] - 21s 74ms/step - loss: 0.4004 - accuracy: 0.8304 - val_loss: 0.3220 - val_accuracy: 0.8977\n",
            "Epoch 3/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8519\n",
            "Epoch 3: val_loss did not improve from 0.32195\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.3831 - accuracy: 0.8519 - val_loss: 0.3899 - val_accuracy: 0.8552\n",
            "Epoch 4/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.8671\n",
            "Epoch 4: val_loss did not improve from 0.32195\n",
            "289/289 [==============================] - 21s 74ms/step - loss: 0.3381 - accuracy: 0.8671 - val_loss: 0.3248 - val_accuracy: 0.9000\n",
            "Epoch 5/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3276 - accuracy: 0.8625\n",
            "Epoch 5: val_loss improved from 0.32195 to 0.27641, saving model to ./model/MobileNet_2.hdf5\n",
            "289/289 [==============================] - 21s 71ms/step - loss: 0.3269 - accuracy: 0.8630 - val_loss: 0.2764 - val_accuracy: 0.8989\n",
            "Epoch 6/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.8826\n",
            "Epoch 6: val_loss improved from 0.27641 to 0.25708, saving model to ./model/MobileNet_2.hdf5\n",
            "289/289 [==============================] - 22s 75ms/step - loss: 0.3020 - accuracy: 0.8824 - val_loss: 0.2571 - val_accuracy: 0.9161\n",
            "Epoch 7/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.8775\n",
            "Epoch 7: val_loss did not improve from 0.25708\n",
            "289/289 [==============================] - 21s 72ms/step - loss: 0.3054 - accuracy: 0.8775 - val_loss: 0.3369 - val_accuracy: 0.8793\n",
            "Epoch 8/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.8782\n",
            "Epoch 8: val_loss did not improve from 0.25708\n",
            "289/289 [==============================] - 21s 74ms/step - loss: 0.3097 - accuracy: 0.8782 - val_loss: 0.2691 - val_accuracy: 0.9011\n",
            "Epoch 9/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.2972 - accuracy: 0.8792\n",
            "Epoch 9: val_loss improved from 0.25708 to 0.22885, saving model to ./model/MobileNet_2.hdf5\n",
            "289/289 [==============================] - 20s 70ms/step - loss: 0.2967 - accuracy: 0.8796 - val_loss: 0.2289 - val_accuracy: 0.9195\n",
            "Epoch 10/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2852 - accuracy: 0.8775\n",
            "Epoch 10: val_loss did not improve from 0.22885\n",
            "289/289 [==============================] - 22s 75ms/step - loss: 0.2852 - accuracy: 0.8775 - val_loss: 0.3377 - val_accuracy: 0.8609\n",
            "Epoch 11/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.8803\n",
            "Epoch 11: val_loss did not improve from 0.22885\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.3012 - accuracy: 0.8803 - val_loss: 0.3008 - val_accuracy: 0.8862\n",
            "Epoch 12/100\n",
            "288/289 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.8903\n",
            "Epoch 12: val_loss did not improve from 0.22885\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.2745 - accuracy: 0.8900 - val_loss: 0.2802 - val_accuracy: 0.8954\n",
            "Epoch 13/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2802 - accuracy: 0.8796\n",
            "Epoch 13: val_loss improved from 0.22885 to 0.21956, saving model to ./model/MobileNet_2.hdf5\n",
            "289/289 [==============================] - 22s 75ms/step - loss: 0.2802 - accuracy: 0.8796 - val_loss: 0.2196 - val_accuracy: 0.9218\n",
            "Epoch 14/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.8879\n",
            "Epoch 14: val_loss did not improve from 0.21956\n",
            "289/289 [==============================] - 20s 68ms/step - loss: 0.2778 - accuracy: 0.8879 - val_loss: 0.2448 - val_accuracy: 0.9069\n",
            "Epoch 15/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.8761\n",
            "Epoch 15: val_loss did not improve from 0.21956\n",
            "289/289 [==============================] - 21s 71ms/step - loss: 0.2807 - accuracy: 0.8761 - val_loss: 0.2787 - val_accuracy: 0.8989\n",
            "Epoch 16/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2608 - accuracy: 0.8879\n",
            "Epoch 16: val_loss did not improve from 0.21956\n",
            "289/289 [==============================] - 21s 74ms/step - loss: 0.2608 - accuracy: 0.8879 - val_loss: 0.2636 - val_accuracy: 0.9046\n",
            "Epoch 17/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.8955\n",
            "Epoch 17: val_loss did not improve from 0.21956\n",
            "289/289 [==============================] - 22s 75ms/step - loss: 0.2685 - accuracy: 0.8955 - val_loss: 0.2380 - val_accuracy: 0.9149\n",
            "Epoch 18/100\n",
            "289/289 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.8886\n",
            "Epoch 18: val_loss did not improve from 0.21956\n",
            "289/289 [==============================] - 24s 82ms/step - loss: 0.2591 - accuracy: 0.8886 - val_loss: 0.3279 - val_accuracy: 0.8667\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.2196 - accuracy: 0.9218\n",
            "Test accuracy: 0.9218390583992004\n"
          ]
        }
      ],
      "source": [
        "transfer_models = [VGG16(weights='imagenet', include_top=False,input_shape=(150,150,3)), InceptionV3(weights='imagenet', include_top=False,input_shape=(150,150,3)), MobileNet(weights='imagenet', include_top=False,input_shape=(150,150,3))]\n",
        "models = ['VGG16.hdf5', 'VGG16_2.hdf5', 'InceptionV3.hdf5', 'InceptionV3_2.hdf5', 'MobileNet.hdf5', 'MobileNet_2.hdf5']\n",
        "\n",
        "model_index = 0\n",
        "for transfer_model in transfer_models:\n",
        "  transfer_model.trainable = False\n",
        "  transfer_model.summary()\n",
        "\n",
        "  for layer in range(1, 3):\n",
        "    finetune_model = Sequential()\n",
        "    finetune_model.add(transfer_model)\n",
        "    finetune_model.add(Flatten())\n",
        "    finetune_model.add(Dense(64 * layer, activation='relu'))\n",
        "    finetune_model.add(Dense(1,activation='sigmoid'))\n",
        "    finetune_model.summary()\n",
        "\n",
        "    finetune_model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
        "\n",
        "    modelpath=\"./model/\" + models[model_index]\n",
        "    checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "    history= finetune_model.fit(train_generator, epochs=100,\n",
        "                      validation_data= test_generator,\n",
        "                      validation_steps= len(test_generator),\n",
        "                      callbacks=[early_stopping_callback,checkpointer])\n",
        "\n",
        "    from tensorflow.keras.models import load_model\n",
        "    bestmodel=load_model(modelpath)\n",
        "    score = bestmodel.evaluate(test_generator, steps=len(test_generator))\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "    model_index += 1"
      ],
      "id": "jYQR37J1X2D-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24b332a8"
      },
      "outputs": [],
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "id": "24b332a8"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}