{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_bu_03_skel-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV1iJazc2fxc",
        "outputId": "79dbe7ad-bf9c-4361-a981-af36ecf89e0e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# Q1) 6개 데이터 샘플을 training 데이터로 입력하시오. 입력값은 (키, 몸무게)(가능한 현실에 있을법한 키(cm)와 몸무게(kg) 값으로 입력하시오.), 출력값은 비만인 경우 (1) 비만이 아닌 경우는 (0)으로 표기할 것.  \n",
        "x_data =  [[180, 64], [160, 71], [173, 97], [178, 58], [181, 115], [159, 45]] ### to do\n",
        "y_data =  [[0], [1], [1], [0], [1], [0]] ### to do\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# Q2) 학습이 진행되도록 알맞은 Optimizer, 학습률을 변경하여 입력하시오. 왜 학습률을 이렇게 하였는가 주석으로 반드시 설명하시오.\n",
        "# 국소최적해에 빠지지 않고 효율적으로 해를 구하려면 학습률을 '처음에는 크게, 그리고 점점 작게'하는 것이 바람직하며, 1e-1부터 수행하여 최적의 비용을 도출해내는 학습률을 사용하였다.\n",
        "optimizer = optim.SGD([W, b], lr=1e-5) ### to do\n",
        "\n",
        "# Q3) 학습이 잘 진행되도록 알맞게 epoch 수를 조정 하시오. 왜 epoch 수를 이렇게 설정 하였는가 주석으로 반드시 설명하시오.\n",
        "# 신뢰도 90%에 근접한 cost 값을 얻을 수 있는 최소한의 횟수를 학습률과 같은 방법으로 도출해냈다.\n",
        "nb_epochs = 10000 ### to do\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = -(y_train * torch.log(hypothesis) + \n",
        "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/10000 Cost: 0.693147\n",
            "Epoch  100/10000 Cost: 0.620182\n",
            "Epoch  200/10000 Cost: 0.561227\n",
            "Epoch  300/10000 Cost: 0.512776\n",
            "Epoch  400/10000 Cost: 0.472614\n",
            "Epoch  500/10000 Cost: 0.438998\n",
            "Epoch  600/10000 Cost: 0.410576\n",
            "Epoch  700/10000 Cost: 0.386304\n",
            "Epoch  800/10000 Cost: 0.365375\n",
            "Epoch  900/10000 Cost: 0.347166\n",
            "Epoch 1000/10000 Cost: 0.331188\n",
            "Epoch 1100/10000 Cost: 0.317059\n",
            "Epoch 1200/10000 Cost: 0.304473\n",
            "Epoch 1300/10000 Cost: 0.293187\n",
            "Epoch 1400/10000 Cost: 0.283006\n",
            "Epoch 1500/10000 Cost: 0.273770\n",
            "Epoch 1600/10000 Cost: 0.265348\n",
            "Epoch 1700/10000 Cost: 0.257631\n",
            "Epoch 1800/10000 Cost: 0.250530\n",
            "Epoch 1900/10000 Cost: 0.243970\n",
            "Epoch 2000/10000 Cost: 0.237886\n",
            "Epoch 2100/10000 Cost: 0.232224\n",
            "Epoch 2200/10000 Cost: 0.226939\n",
            "Epoch 2300/10000 Cost: 0.221991\n",
            "Epoch 2400/10000 Cost: 0.217345\n",
            "Epoch 2500/10000 Cost: 0.212973\n",
            "Epoch 2600/10000 Cost: 0.208847\n",
            "Epoch 2700/10000 Cost: 0.204945\n",
            "Epoch 2800/10000 Cost: 0.201248\n",
            "Epoch 2900/10000 Cost: 0.197737\n",
            "Epoch 3000/10000 Cost: 0.194398\n",
            "Epoch 3100/10000 Cost: 0.191217\n",
            "Epoch 3200/10000 Cost: 0.188180\n",
            "Epoch 3300/10000 Cost: 0.185278\n",
            "Epoch 3400/10000 Cost: 0.182499\n",
            "Epoch 3500/10000 Cost: 0.179836\n",
            "Epoch 3600/10000 Cost: 0.177280\n",
            "Epoch 3700/10000 Cost: 0.174824\n",
            "Epoch 3800/10000 Cost: 0.172461\n",
            "Epoch 3900/10000 Cost: 0.170185\n",
            "Epoch 4000/10000 Cost: 0.167991\n",
            "Epoch 4100/10000 Cost: 0.165873\n",
            "Epoch 4200/10000 Cost: 0.163828\n",
            "Epoch 4300/10000 Cost: 0.161851\n",
            "Epoch 4400/10000 Cost: 0.159937\n",
            "Epoch 4500/10000 Cost: 0.158084\n",
            "Epoch 4600/10000 Cost: 0.156288\n",
            "Epoch 4700/10000 Cost: 0.154547\n",
            "Epoch 4800/10000 Cost: 0.152856\n",
            "Epoch 4900/10000 Cost: 0.151214\n",
            "Epoch 5000/10000 Cost: 0.149619\n",
            "Epoch 5100/10000 Cost: 0.148067\n",
            "Epoch 5200/10000 Cost: 0.146557\n",
            "Epoch 5300/10000 Cost: 0.145088\n",
            "Epoch 5400/10000 Cost: 0.143656\n",
            "Epoch 5500/10000 Cost: 0.142260\n",
            "Epoch 5600/10000 Cost: 0.140900\n",
            "Epoch 5700/10000 Cost: 0.139573\n",
            "Epoch 5800/10000 Cost: 0.138277\n",
            "Epoch 5900/10000 Cost: 0.137012\n",
            "Epoch 6000/10000 Cost: 0.135776\n",
            "Epoch 6100/10000 Cost: 0.134569\n",
            "Epoch 6200/10000 Cost: 0.133388\n",
            "Epoch 6300/10000 Cost: 0.132233\n",
            "Epoch 6400/10000 Cost: 0.131104\n",
            "Epoch 6500/10000 Cost: 0.129998\n",
            "Epoch 6600/10000 Cost: 0.128915\n",
            "Epoch 6700/10000 Cost: 0.127855\n",
            "Epoch 6800/10000 Cost: 0.126816\n",
            "Epoch 6900/10000 Cost: 0.125798\n",
            "Epoch 7000/10000 Cost: 0.124800\n",
            "Epoch 7100/10000 Cost: 0.123821\n",
            "Epoch 7200/10000 Cost: 0.122861\n",
            "Epoch 7300/10000 Cost: 0.121919\n",
            "Epoch 7400/10000 Cost: 0.120994\n",
            "Epoch 7500/10000 Cost: 0.120086\n",
            "Epoch 7600/10000 Cost: 0.119195\n",
            "Epoch 7700/10000 Cost: 0.118320\n",
            "Epoch 7800/10000 Cost: 0.117460\n",
            "Epoch 7900/10000 Cost: 0.116615\n",
            "Epoch 8000/10000 Cost: 0.115784\n",
            "Epoch 8100/10000 Cost: 0.114968\n",
            "Epoch 8200/10000 Cost: 0.114165\n",
            "Epoch 8300/10000 Cost: 0.113375\n",
            "Epoch 8400/10000 Cost: 0.112599\n",
            "Epoch 8500/10000 Cost: 0.111835\n",
            "Epoch 8600/10000 Cost: 0.111083\n",
            "Epoch 8700/10000 Cost: 0.110342\n",
            "Epoch 8800/10000 Cost: 0.109614\n",
            "Epoch 8900/10000 Cost: 0.108896\n",
            "Epoch 9000/10000 Cost: 0.108190\n",
            "Epoch 9100/10000 Cost: 0.107494\n",
            "Epoch 9200/10000 Cost: 0.106809\n",
            "Epoch 9300/10000 Cost: 0.106134\n",
            "Epoch 9400/10000 Cost: 0.105468\n",
            "Epoch 9500/10000 Cost: 0.104812\n",
            "Epoch 9600/10000 Cost: 0.104166\n",
            "Epoch 9700/10000 Cost: 0.103529\n",
            "Epoch 9800/10000 Cost: 0.102900\n",
            "Epoch 9900/10000 Cost: 0.102281\n",
            "Epoch 10000/10000 Cost: 0.101670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIoZFglt3Hwr",
        "outputId": "5e8b1f35-79f1-42f4-80dd-01b9a55d9073"
      },
      "source": [
        "# Q4) x_test에 적당한 입력(키, 몸무게)를 입력하여 결과를 확인하시오.\n",
        "x_test = torch.FloatTensor([178, 71])### to do\n",
        "hypothesis = torch.sigmoid(x_test.matmul(W) + b)\n",
        "cost = -(y_train * torch.log(hypothesis) + \n",
        "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "print (hypothesis >= torch.FloatTensor([0.5]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False])\n"
          ]
        }
      ]
    }
  ]
}